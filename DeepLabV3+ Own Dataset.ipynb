{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 11\u001B[0m\n\u001B[0;32m      5\u001B[0m transform \u001B[38;5;241m=\u001B[39m T\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      6\u001B[0m     T\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[0;32m      7\u001B[0m     T\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.485\u001B[39m, \u001B[38;5;241m0.456\u001B[39m, \u001B[38;5;241m0.406\u001B[39m], std\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.229\u001B[39m, \u001B[38;5;241m0.224\u001B[39m, \u001B[38;5;241m0.225\u001B[39m]),\n\u001B[0;32m      8\u001B[0m ])\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Load the training and validation datasets\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCocoDetection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdatasets/facades/train\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mannFile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdatasets/facades/train/_annotations.coco.json\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m valid_dataset \u001B[38;5;241m=\u001B[39m CocoDetection(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatasets/facades/valid\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     16\u001B[0m                               annFile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatasets/facades/valid/_annotations.coco.json\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     17\u001B[0m                               transform\u001B[38;5;241m=\u001B[39mtransform)\n\u001B[0;32m     19\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m CocoDetection(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatasets/facades/test\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     20\u001B[0m                               annFile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatasets/facades/test/_annotations.coco.json\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     21\u001B[0m                               transform\u001B[38;5;241m=\u001B[39mtransform)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\coco.py:34\u001B[0m, in \u001B[0;36mCocoDetection.__init__\u001B[1;34m(self, root, annFile, transform, target_transform, transforms)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     27\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     31\u001B[0m     transforms: Optional[Callable] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     32\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transforms, transform, target_transform)\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpycocotools\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcoco\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m COCO\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoco \u001B[38;5;241m=\u001B[39m COCO(annFile)\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoco\u001B[38;5;241m.\u001B[39mimgs\u001B[38;5;241m.\u001B[39mkeys()))\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "# Define the transformations for preprocessing\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_dataset = CocoDetection(root='datasets/facades/train',\n",
    "                              annFile='datasets/facades/train/_annotations.coco.json',\n",
    "                              transform=transform)\n",
    "\n",
    "valid_dataset = CocoDetection(root='datasets/facades/valid',\n",
    "                              annFile='datasets/facades/valid/_annotations.coco.json',\n",
    "                              transform=transform)\n",
    "\n",
    "test_dataset = CocoDetection(root='datasets/facades/test',\n",
    "                              annFile='datasets/facades/test/_annotations.coco.json',\n",
    "                              transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "# etc. for the test loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}